{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import Tag\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data & Parse data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../scraped_page.html', 'r', encoding='utf-8') as file:\n",
    "    html_content = file.read()\n",
    "\n",
    "soup = BeautifulSoup(html_content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "li_elements = soup.select('li.search-container_level.u-flex.u-flex_column.u-gap_16.u-border_rim.u-rounded.u-bg_bg-secondary')\n",
    "n_levels = {\n",
    "    'N5': [],\n",
    "    'N4': [],\n",
    "    'N3': [],\n",
    "    'N2': [],\n",
    "    'N1': [],\n",
    "    'Non-JLPT': []\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level N5 has 126 grammar points\n",
      "Level N4 has 177 grammar points\n",
      "Level N3 has 219 grammar points\n",
      "Level N2 has 213 grammar points\n",
      "Level N1 has 180 grammar points\n",
      "Level Non-JLPT has 12 grammar points\n"
     ]
    }
   ],
   "source": [
    "for element in li_elements:\n",
    "    # Find the level from the <h2> tag\n",
    "    level = element.select_one('h2').text.strip()\n",
    "\n",
    "    # Check if level is in the dictionary (to avoid KeyError)\n",
    "    if level in n_levels:\n",
    "        # Find all <li> elements with the 'data-grammar-point' attribute\n",
    "        a = element.select('li[data-grammar-point]')\n",
    "\n",
    "        # Extract 'data-grammar-point' attribute values\n",
    "        grammar_points = [item['data-grammar-point'] for item in a]\n",
    "\n",
    "        # Append the extracted grammar points to the correct level\n",
    "        n_levels[level] = grammar_points\n",
    "\n",
    "# Print the dictionary to see the populated values\n",
    "for level, grammar_points in n_levels.items():\n",
    "    print(f\"Level {level} has {len(grammar_points)} grammar points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dictionary to a file\n",
    "with open('grammar_points.json', 'w', encoding='utf-8') as file:\n",
    "    json.dump(n_levels, file, ensure_ascii=False, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scrape",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
